# 🤖 Chatbot

An interactive **Streamlit chatbot app** powered by **Gemini 1.5 Flash**, allowing users to upload images and documents and ask questions based on their content.

<p align="center">
  <img src="https://github.com/DanialSoleimany/chatbot-streamlit/blob/main/chatbot.png?raw=true" alt="Chatbot Screenshot" width="80%">
</p>

## 📚 Table of Contents

- [🚀 Overview](#-overview)
- [🖼 Features](#-features)
- [📦 Installation](#-installation)
- [⚙️ Configuration](#-configuration)
- [🧪 Usage](#-usage)
- [📁 Project Structure](#-project-structure)
- [🛡 Security](#-security)
- [🧠 Example Prompts](#-example-prompts)
- [📌 TODOs](#-todos)
- [⚠️ Current Challenges](#-current-challenges)
- [🤝 License](#-license)

---

## 🚀 Overview

This app enables users to:

- Upload **multiple images** (`.jpg`, `.png`, etc.)
- Upload **multiple documents** (`.pdf`, `.docx`, `.txt`)
- Ask natural language questions
- Get answers generated by **Gemini 1.5 Flash**
- Automatically extract and process only relevant data (e.g., just the PDF content)

---

## 🖼 Features

- ✅ Supports multi-file upload (images & documents)
- ✅ Real-time chat history
- ✅ Dynamic context selection based on question
- ✅ Clean UI using Streamlit
- ✅ Secure API key handling via `secrets.toml`

---

## 📦 Installation

```bash
git clone https://github.com/your-username/gemini-flash-chatbot.git
cd gemini-flash-chatbot
pip install -r requirements.txt
⚙️ Configuration
Create a .streamlit/secrets.toml file with the following content:

GEMINI_API_KEY = "your_google_generative_ai_key"
⚠️ Note: Never commit this file to source control! It contains sensitive keys.

🧪 Usage
```bash
streamlit run app.py
After launching:

Upload images and/or documents using the uploader panel.

### Ask questions like:
- “What does the PDF say about climate change?”
- “Summarize the text documents”
- “Describe the uploaded images”
- Get real-time, AI-generated responses using Gemini Flash.

📁 Project Structure
chatbot-streamlit/
├── app.py                 # Main Streamlit app
├── .streamlit/
│   └── secrets.toml       # API key config (ignored by git)
├── requirements.txt       # Python dependencies
└── README.md
🛡 Security
All secrets are stored in .streamlit/secrets.toml

Git-ignored by default

Always treat API keys as sensitive!
- 🧠 Example Prompts
- 📝 "Summarize the uploaded PDF"
- 🖼 "Describe what's in the images"
- 📚 "Compare the content of all documents"
- 📄 "Extract keywords from the DOCX file"

## 📌 TODOs
🔧 Functionality
- Add image preview panel
- Add per-file action buttons (analyze/download)
- Add support for more file formats (.csv, .pptx, .md, etc.)
- Add ComboBox for selecting from multiple LLMs (Gemini, OpenAI, Claude, etc.)
- Support multiple API providers with separate API keys
- Add support for image generation via prompt (text-to-image)

## 🧠 User Experience
- Deploy to Streamlit Cloud
- Make chat history searchable
- Add response export (e.g., save chat as PDF or markdown)
- Add per-question response timestamp
- Enable theme switching (light/dark mode)

🧪 Developer Tools
- Add logging for debugging
- Add unit tests for file parsing
- Refactor file processing logic into reusable modules
- Add support for user login / session management
- Cache previous responses to reduce API calls

## ⚠️ Current Challenges
🔁 Chat History Management
Currently, chat history is managed using st.session_state.messages, which stores each user and AI message in chronological order. This maintains conversational flow within a session.

However, referencing a specific uploaded item (e.g., “describe the second image”) remains a challenge.
- Planned Improvements:
- File indexing and labeling in UI (e.g., “File 1: chart.png”)
- Linking follow-up questions to specific files
- Better context caching and relevance tracking

⛔ API Context Limitations
The Gemini 1.5 Flash model has a limited context window, meaning it can only process a certain number of tokens (text + image) at a time.

### Current limitations:
- Only the most relevant portions of content are passed to the model
- Context selection is heuristic and not always accurate
- Large mixed media inputs may lead to incomplete responses

📌 Planned Fixes
- Add metadata-aware file indexing
- Improve prompt design for better file reference resolution
- Implement chunk scoring and filtering logic
- Explore integration with vector stores (e.g., FAISS, Pinecone) for smarter retrieval

🤝 License
MIT License © 2025 [Danial Soleimany]
